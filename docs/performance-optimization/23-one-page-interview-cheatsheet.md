# One-Page Interview Cheatsheet

## 1) 핵심 성과 3줄

- Notepad 목록: queries `22 -> 4`, elapsed `15ms -> 4ms`
- Dashboard 통계: queries `13 -> 10`, elapsed `14ms -> 2ms`
- Refresh 재발급: avg `32ms -> 9ms`, p95 `78ms -> 21ms`

## 2) 내가 한 일(순서)

1. N+1 제거 (읽음 수 건별 조회 -> IN + GROUP BY 일괄 집계)
2. 집계 쿼리 전환 (목록 로딩 후 Java 계산 -> DB 집계)
3. 인덱스 튜닝 (EXPLAIN 기준 `ALL/filesort` -> `ref/range`)
4. Redis 인증 경로 정리 (단일 키 O(1), TTL/직렬화 표준화)

## 3) 실패/시행착오 2개

- 페이징 구간에서 fetch join을 무리하게 적용했다가 중복/카운트 이슈 확인 후 철회
- Redis 도입 초기에 TTL 누락/포맷 혼재로 간헐 오류 발생, 저장 API/포맷 단일화로 해결

## 4) 트레이드오프 2개

- 인덱스는 read 성능 향상 대신 write 비용/스토리지 증가
- 캐시는 응답시간 개선 대신 무효화/정합성 관리 비용 증가

## 5) 신뢰성 답변 프레임

- H2는 회귀 감지용, 최종 검증은 MySQL EXPLAIN/slow query로 보완
- 정량 지표는 avg/p95/queries를 동일 시나리오로 전후 비교

## 6) 마무리 한 문장

"저는 성능 개선을 기법 나열이 아니라, 병목 재현 -> 원인 분리 -> 단계별 개선 -> MySQL 검증까지 닫는 과정으로 수행합니다."

## 7) 말하기 스크립트 (30초/60초/90초)

### 30초 버전

"유치원 ERP에서 성능 병목을 감이 아니라 수치로 재현하고 단계적으로 개선했습니다.
알림장 목록은 N+1 제거로 쿼리 수를 22에서 4로 줄였고,
대시보드 통계는 집계 쿼리 전환으로 14ms에서 2ms까지 줄였습니다.
최종 검증은 H2가 아니라 MySQL EXPLAIN과 slow query 기준으로 확인했습니다."

### 60초 버전

"기능 완성 후 데이터가 늘면서 알림장과 대시보드에서 지연이 튀는 문제가 있었습니다.
먼저 시나리오를 고정하고 avg/p95/쿼리 수를 측정해 병목을 분리했습니다.
1단계로 알림장 readCount N+1을 IN + GROUP BY 집계로 바꿔 queries 22에서 4,
elapsed 15ms에서 4ms로 개선했습니다.
2단계로 대시보드 계산을 Java 루프에서 DB 집계로 옮겨 queries 13에서 10,
elapsed 14ms에서 2ms로 낮췄습니다.
3단계로 인덱스를 튜닝해 EXPLAIN에서 ALL/filesort를 ref/range로 전환했습니다.
핵심은 H2는 회귀 감지에만 쓰고, 최종 타당성은 MySQL 검증으로 닫았다는 점입니다."

### 90초 버전

"저는 성능 개선을 한 번의 트릭이 아니라 재현 가능한 과정으로 접근합니다.
이 프로젝트에서도 먼저 사용자 체감이 큰 알림장 목록과 대시보드를 대상으로,
동일 시나리오에서 avg/p95/쿼리 수를 측정해 병목을 확정했습니다.

첫 번째 병목은 알림장 목록의 N+1이었습니다.
페이지 내 건별 읽음 조회를 일괄 집계로 전환해 queries 22에서 4,
elapsed 15ms에서 4ms로 줄였습니다.

두 번째는 대시보드 통계 경로였습니다.
목록을 가져와 Java에서 계산하던 구조를 DB 집계로 바꿔
queries 13에서 10, elapsed 14ms에서 2ms로 개선했습니다.

세 번째는 실행계획 최적화였습니다.
복합 인덱스를 where/order/join 패턴 기준으로 설계하고,
MySQL EXPLAIN에서 ALL/filesort가 ref/range로 바뀐 것을 확인했습니다.

또 Redis 인증 경로에서는 `refresh:{email}` 단일 키, set+TTL 표준화로
재발급 평균 32ms에서 9ms, p95 78ms에서 21ms를 확인했습니다.

제가 강조하는 포인트는 세 가지입니다.
첫째, H2는 회귀 감지용이고 최종 근거는 MySQL입니다.
둘째, 수치뿐 아니라 실패와 트레이드오프를 함께 설명합니다.
셋째, 문서-코드-테스트를 1:1로 연결해 검증 가능성을 보장합니다."

## 8) 면접 질문별 답변 재배치

### Q1. 무엇을 개선했나요? (핵심 요약)

"알림장 N+1 제거, 대시보드 집계 쿼리 전환, 인덱스 튜닝, Redis 인증 경로 최적화를 순차적으로 진행했습니다.
결과적으로 Notepad는 queries 22에서 4, Dashboard는 14ms에서 2ms,
Refresh 재발급은 p95 78ms에서 21ms까지 개선했습니다."

### Q2. 왜 그 순서로 개선했나요?

"캐시를 먼저 붙이면 원인이 가려질 수 있어서,
N+1 같은 구조적 낭비를 먼저 제거하고 집계 경로를 정리한 뒤,
마지막에 인덱스로 실행계획을 마무리했습니다.
이 순서가 단계별 효과를 분리해서 증명하기 가장 좋았습니다."

### Q3. 성능 수치가 신뢰 가능한가요?

"동일 시나리오/동일 데이터/동일 환경으로 전후 비교했고,
H2는 회귀 감지용으로 사용했습니다.
최종 타당성은 MySQL EXPLAIN과 slow query로 교차 검증했습니다.
즉, 테스트 편의성과 운영 신뢰성을 분리해서 관리했습니다."

### Q4. 적용 중 어려움이나 실패는 무엇이었나요?

"페이징 구간에서 fetch join을 무리하게 적용했다가 중복/카운트 이슈를 겪어 철회했고,
Redis에서는 TTL 누락과 직렬화 혼재로 간헐 오류가 발생했습니다.
이후 저장 API 단일화(set+TTL), 포맷 통일(String), 키 규칙 고정으로 재발을 막았습니다."

### Q5. 트레이드오프는 어떻게 관리했나요?

"인덱스는 read 성능을 높이지만 write 비용이 증가하고,
캐시는 응답시간을 줄이지만 무효화 복잡도가 올라갑니다.
그래서 조회 상위 경로에만 제한 적용하고,
slow query 점검과 캐시 무효화 테스트를 운영 체크리스트로 고정했습니다."

### Q6. 본인이 만든 가치는 무엇인가요?

"수치를 낮춘 것 자체보다,
병목 재현 -> 단계별 개선 -> MySQL 검증 -> 문서/테스트 증빙까지
팀이 재사용 가능한 성능 개선 프로세스를 만든 점이 가장 큰 가치입니다."
