# 2026-02-14 성능 개선 스크립트 (면접/발표용)

## 15초 한 줄 소개

"유치원 ERP에서 느린 구간을 감이 아니라 수치로 재현한 뒤,
N+1 제거 -> 집계 쿼리 전환 -> 인덱스 튜닝을 단계적으로 적용해
쿼리 수와 지연시간을 안정적으로 줄인 경험이 있습니다."

## 20초 오프닝 (면접 첫 답변)

저는 성능 개선을 "한 번에 크게 바꾸는 작업"보다,
병목을 재현하고 원인을 분리해서 한 단계씩 줄여가는 과정으로 접근합니다.
이 프로젝트에서도 캐시를 먼저 붙이지 않고,
N+1 제거, 집계 쿼리 전환, 인덱스 튜닝 순서로 개선 효과를 분리 검증했습니다.

## 왜 개선을 시작했는지 (문제 인식)

초기 목표는 기능 완성이어서, 알림장/대시보드 API는 "정답은 맞지만 비용이 큰" 형태였습니다.

- 알림장 목록: 페이지당 알림장마다 읽음 수를 추가 조회
- 대시보드 통계: 목록을 먼저 가져온 뒤 Java 코드에서 합산/비율 계산
- 공통 문제: 데이터가 늘수록 API 지연 분산이 커지고, 피크 시간대 p95가 튐

사용자 피드백은 "항상 느리다"가 아니라 "가끔 버벅인다"였고,
이 유형은 보통 평균보다 상위 지연(p95/p99)에서 먼저 드러납니다.
그래서 개선 목표를 "코드 깔끔화"가 아니라 **상위 지연 안정화**로 잡았습니다.

## 측정 방식 (재현 시나리오 고정)

AGENTS 성능 스토리 규칙에 맞춰 아래 순서로 진행했습니다.

1. 재현 시나리오 정의
2. 개선 전 측정(쿼리 수 + 응답 시간)
3. 개선 적용(단계별 1개 주제)
4. 동일 시나리오 재측정
5. 결과/트레이드오프 문서화

### 신뢰성 원칙 (MySQL 중심)

- 회귀 감지: H2 테스트 결과로 빠르게 비교
- 최종 타당성: MySQL EXPLAIN/slow query로 교차 검증
- 면접 답변: "H2 결과 -> MySQL 근거" 순서로 제시

### 시나리오 A: 알림장 목록 API

- 조건: 같은 원/같은 반/페이지 크기 20/동일 데이터셋
- 측정: 요청 1회당 SQL 쿼리 수, API elapsed time

### 시나리오 B: 대시보드 통계 API

- 조건: 동일 기간(이번 달), 동일 교사 권한, 동일 데이터셋
- 측정: 통계 조회 쿼리 수, API elapsed time, EXPLAIN 실행계획

## 개선 여정 (스토리 중심)

### 1단계. N+1 제거: "눈에 보이는 낭비"부터 줄이기

처음에는 알림장 목록에서 "본문 조회 1번 + 읽음 수 N번"이 반복됐습니다.
데이터가 적을 땐 티가 안 났지만, 페이지 사이즈가 커지면 쿼리가 급증했습니다.

#### 당시 고충

- 코드 상으로는 간단한 루프라 리뷰에서 놓치기 쉬움
- 개발 DB 데이터가 적어 로컬에서는 느려짐이 약하게 보임
- 응답 DTO를 만들 때 "필요한 값만 즉시 조회" 습관이 N+1로 연결됨

#### 어떻게 방법을 찾았는지

Hibernate SQL 로그를 켜고 요청 1건의 쿼리를 직접 세어보니,
"목록 수만큼 동일 패턴 쿼리 반복"이 명확히 보였습니다.
여기서 "fetch join으로 한 번에 가져오면 끝 아닌가"를 먼저 시도했지만,
페이징 + 조인 카디널리티 문제로 count 부정확/중복 리스크가 보여 채택하지 않았습니다.

#### 적용

- 페이지의 알림장 ID 목록을 먼저 확보
- 읽음 수를 `where in (:ids) group by notepad_id` 형태로 일괄 집계
- 결과를 Map으로 매핑해 DTO 조립

#### 1단계 결과

- Notepad 목록: queries **22 -> 4**, elapsed **15ms -> 8ms**

#### 1단계에서 배운 점

- N+1은 "ORM 문제"가 아니라 "조회 경계 설계 문제"
- 페이징 화면에서는 fetch join보다 "2-step 조회 + 집계"가 더 안전할 때가 많음
- 성능 개선은 우선 쿼리 수를 줄이면, 이후 단계(인덱스)의 효과가 더 선명해짐

---

### 2단계. 집계 쿼리 전환: "애플리케이션 계산"을 DB 집계로 이동

N+1을 줄인 뒤에도 대시보드는 아직 들쭉날쭉했습니다.
원인을 다시 보니, 데이터를 많이 읽어와 Java에서 계산하는 비용이 남아 있었습니다.

#### 당시 고충

- 통계 요구사항이 늘며 "일단 목록 로드 후 계산" 코드가 누적
- 계산식이 서비스에 흩어져 변경 영향 범위가 넓음
- 쿼리 수만 보면 큰 문제 없어 보이는데, 전송/객체화 비용이 숨어 있음

#### 어떻게 방법을 알게됐는지

프로파일링 시 DB time보다 애플리케이션 객체 생성/순회 비용이 무시 못 할 수준이었고,
통계성 API는 "row를 가져오는 API"가 아니라 "숫자를 반환하는 API"라는 점을 다시 정리했습니다.

#### 적용

- 출석률: PRESENT/LATE를 각각 세던 방식 -> 조건부 집계 1회로 통합
- 공지 열람률: 공지 목록 로딩 후 합산 -> `SUM(view_count)` 직접 집계
- 서비스 계층에서는 집계 결과를 바로 응답 DTO로 매핑

#### 2단계 결과

- Dashboard 통계: queries **13 -> 10**, elapsed **14ms -> 5ms**
- Notepad 목록(1단계 유지): elapsed **8ms** 수준 유지

#### 2단계에서 배운 점

- 쿼리 수가 전부는 아님: "얼마나 많은 row를 앱으로 끌고 왔는가"가 중요
- 통계 API는 처음부터 집계 중심으로 모델링해야 변경 비용이 낮음
- "DB가 계산할 것"과 "앱이 계산할 것"의 경계를 명확히 해야 함

---

### 3단계. 인덱스 튜닝: "좋은 쿼리"를 "좋은 실행계획"으로 완성

N+1 제거와 집계 전환 후 평균은 좋아졌지만,
특정 조건/정렬에서 여전히 느린 케이스가 남았습니다.
여기서 처음으로 EXPLAIN을 본격 도입했습니다.

#### 당시 고충

- 쿼리는 깔끔해 보이는데 실제 실행계획은 ALL/filesort
- 단일 인덱스는 있어도 `where + order by` 복합 패턴을 못 타는 상황
- 인덱스 추가 시 쓰기 비용 증가가 걱정됨

#### 어떻게 방법을 알게됐는지

실행계획에서 type, key, rows, extra를 비교하면서,
실제 트래픽 경로의 조건식/정렬 기준에 맞춰 복합 인덱스를 설계해야 한다는 점을 체감했습니다.

#### 적용

- 조회 빈도 높은 조건(`kindergarten_id`, `classroom_id`, `created_at`) 기준 복합 인덱스 구성
- 통계 쿼리 조인 키와 필터 컬럼 순서 재점검
- EXPLAIN에서 ALL/filesort 제거 여부 확인 후 반영

#### 3단계 결과

- Notepad 목록: elapsed **8ms -> 4ms**
- Dashboard 통계: elapsed **5ms -> 2ms**
- 실행계획: ALL/filesort 다수 구간이 ref/range 중심으로 전환

#### 3단계에서 배운 점

- 인덱스는 "많이"가 아니라 "조회 패턴에 정확히"가 핵심
- 쿼리 리팩터링 후 인덱스 튜닝을 해야 과최적화를 줄일 수 있음
- 성능 개선은 코드/DB를 따로 보지 말고 하나의 요청 경로로 봐야 함

## 단계별 전후 수치 (같은 시나리오 기준)

### Notepad 목록 API

- 개선 전: queries 22, elapsed 15ms
- 1단계(N+1 제거) 후: queries 4, elapsed 8ms
- 3단계(인덱스 튜닝) 후: queries 4, elapsed 4ms

### Dashboard 통계 API

- 개선 전: queries 13, elapsed 14ms
- 2단계(집계 쿼리 전환) 후: queries 10, elapsed 5ms
- 3단계(인덱스 튜닝) 후: queries 10, elapsed 2ms

### 부하 관점 참고

- k6 동시성 테스트: Notepad p95 45.32ms, Dashboard p95 27.88ms, 에러율 0.00%

## 30초 버전

이 프로젝트 성능 개선은 세 가지를 한 번에 바꾼 게 아니라,
N+1 제거, 집계 쿼리 전환, 인덱스 튜닝을 단계적으로 나눠 적용했습니다.
먼저 알림장 목록의 N+1을 제거해 쿼리를 22에서 4로 줄였고,
그다음 대시보드의 앱 계산 로직을 DB 집계로 옮겨 14ms를 5ms로 낮췄습니다.
마지막으로 EXPLAIN 기반 인덱스 튜닝으로 상위 지연까지 안정화해
최종적으로 Notepad 15ms -> 4ms, Dashboard 14ms -> 2ms를 만들었습니다.

## 1분 버전 (실전 답변)

초기에는 기능을 빠르게 완성하느라 조회 비용이 큰 코드가 남아 있었습니다.
그래서 먼저 시나리오를 고정해 쿼리 수와 응답시간을 측정했고,
한 번에 다 바꾸지 않고 원인을 분리해 3단계로 개선했습니다.

1단계는 알림장 목록의 N+1 제거였습니다.
페이지 내 건별 조회를 IN + GROUP BY 집계로 바꿔 쿼리를 22에서 4로 줄였고,
응답시간은 15ms에서 8ms로 감소했습니다.

2단계는 대시보드 집계 전환이었습니다.
목록을 가져와 Java에서 계산하던 구조를 DB 집계로 옮겨
쿼리는 13에서 10, 응답시간은 14ms에서 5ms로 줄였습니다.

3단계는 인덱스 튜닝이었습니다.
EXPLAIN으로 ALL/filesort를 확인하고 복합 인덱스를 조정해
Notepad를 4ms, Dashboard를 2ms까지 낮췄습니다.

핵심은 "기술을 많이 썼다"가 아니라,
단계별로 원인과 효과를 분리해 설명 가능한 개선을 만들었다는 점입니다.

## 3분 버전 (깊이 질문 대응)

### 1) 왜 캐시보다 이 세 가지를 먼저 했는가

캐시는 빠르게 보이게 할 수 있지만, 원인을 가립니다.
저는 먼저 조회 구조를 정상화해야 이후 캐시 정책도 단순해진다고 판단했습니다.
즉, N+1/집계/인덱스는 캐시 이전의 "기본 체력" 개선이었습니다.

### 2) 왜 이 순서였는가

- 1순위 N+1 제거: 가장 큰 낭비를 즉시 제거
- 2순위 집계 전환: 데이터 전송/객체화 비용 절감
- 3순위 인덱스 튜닝: 남은 병목을 실행계획 단에서 정리

이 순서로 해야 각 단계 효과를 분리해서 증명할 수 있고,
문제 발생 시 롤백 범위도 작아집니다.

### 3) 적용 중 실수/시행착오

- 페이징 화면에 무리한 fetch join을 시도했다가 중복/카운트 이슈 확인
- 쿼리 수만 보고 "끝"이라고 판단했다가 앱 계산 비용을 놓침
- 인덱스를 넓게 추가하려다 쓰기 비용을 고려해 최소 세트로 재조정

### 4) 지금 다시 한다면 무엇을 다르게 할지

- 기능 개발 초기부터 "통계 API는 집계 중심"으로 모델링
- API 설계 리뷰에 EXPLAIN 체크리스트를 기본 포함
- 성능 테스트를 릴리즈 직전이 아니라 기능 완료 직후 주기적으로 실행

## 꼬리 질문 대응 템플릿

### Q1. N+1 제거에서 가장 중요한 판단은?

페이징 화면에서는 fetch join 만능주의를 버리고,
ID 조회 + 집계 조회의 2-step 전략이 더 안전하다는 판단이었습니다.

### Q2. 집계 쿼리 전환의 핵심 이득은?

쿼리 수 감소보다 "불필요한 row 전송/객체화 제거"가 더 컸습니다.
그래서 p95 안정화에 직접적인 효과가 있었습니다.

### Q3. 인덱스는 어떻게 검증했나?

`where + order by + join` 실제 패턴 기반으로 설계했고,
EXPLAIN에서 ALL/filesort 제거와 rows 감소를 함께 확인했습니다.

### Q4. 트레이드오프는?

인덱스는 쓰기 비용/저장공간을 늘립니다.
그래서 조회 상위 경로에만 제한적으로 적용하고,
slow query log 기반으로 주기 점검하는 운영 계획을 함께 세웠습니다.

## 최종 메시지 (면접 마무리)

이번 성능 개선의 포인트는
"세 기술을 적용했다"가 아니라,
"단계별로 원인을 분리하고, 수치로 검증하고, 트레이드오프까지 설명 가능한 상태로 만든 것"입니다.

## 실전 모의면접 운영 (통합)

### 25분 진행안

- 1분: 20초 자기소개 + 40초 핵심 사례
- 10분: 기본 질문 5개(병목 탐지, N+1, 집계, 인덱스, 검증)
- 10분: 압박 질문 5개(H2 신뢰성, 개선 폭, 캐시 우선순위, 쓰기 비용, UX 체감)
- 4분: 피드백 반영 재답변

### 답변 점검 체크리스트

- 숫자를 먼저 말했는가? (예: 22 -> 4)
- 원인을 한 줄로 설명했는가? (예: readCount N+1)
- 해결 방법이 구체적인가? (집계 쿼리/인덱스/실행계획)
- 검증 근거를 제시했는가? (테스트 로그/EXPLAIN)
- 트레이드오프를 인정했는가?

### 압박 질문 핵심 답변 프레임

- "수치가 작다" -> 절대값보다 동일 조건 상대 개선과 구조 개선(쿼리 수) 강조
- "H2가 무의미하다" -> H2는 회귀 감지용, MySQL EXPLAIN/slow query 전후로 보완
- "캐시를 먼저 쓰지" -> 캐시는 증상 완화, N+1/집계는 원인 제거
- "인덱스 쓰기 비용" -> 인정 + 조회 중심 트래픽 근거 + slow query 정기 점검
- "체감 개선 근거" -> elapsed + p95 + 에러율까지 함께 제시

## 관련 문서

- `docs/performance-optimization/03-notepad-readcount-nplusone.md`
- `docs/performance-optimization/04-dashboard-stats.md`
- `docs/performance-optimization/05-index-tuning-dashboard-notepad.md`
- `docs/performance-optimization/07-redis-adoption-story-script.md`
- `docs/performance-optimization/00-portfolio-storytelling-roadmap.md`
- `docs/performance-optimization/02-mysql-validation-report.md`
- `docs/performance-optimization/22-code-test-evidence-map.md`
- `docs/performance-optimization/23-one-page-interview-cheatsheet.md`
